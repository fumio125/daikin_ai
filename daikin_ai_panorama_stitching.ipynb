{"cells":[{"cell_type":"markdown","source":["準備：`images.zip`に入っている画像をcolabに投げ込んでください"],"metadata":{"id":"YpYAmKOG-QhH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-fMI1Zk2pcp"},"outputs":[],"source":["import cv2\n","import numpy as np  # PythonのOpenCVでは、画像はnumpyのarrayとして管理される\n","from google.colab.patches import cv2_imshow # colab内で画像表示関数がうまく動かないので、パッチが提供されている"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7hEMsvFE22S7"},"outputs":[],"source":["# imgをrefに張り合わせることを考える\n","ref = cv2.imread(\"pano_ref.jpg\") # ベースとなる画像（BGR）\n","src = cv2.imread(\"pano_src.jpg\") # 変換する画像（BGR）"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibRxk00XoZGd"},"outputs":[],"source":["# ratio test ありの場合\n","# https://docs.opencv.org/master/db/d27/tutorial_py_table_of_contents_feature2d.html\n","\n","# ORB を使う場合。AKAZEならAKAZE_create、SIFTならSIFT_create\n","orb = cv2.ORB_create()\n","\n","# 各画像に対するkeypointとdescriptorの計算\n","kp_ref, des_ref = orb.detectAndCompute(ref, None)\n","kp_src, des_src = orb.detectAndCompute(src, None)\n","\n","# マッチング。ORBならHAMMING距離をつかうべき\n","matcher = cv2.BFMatcher(cv2.NORM_HAMMING) #, crossCheck=True) # knn matchのときはcross checkは使えない\n","matches = matcher.knnMatch(des_ref,des_src,k=2)\n","#matches = matcher.match(des_ref,des_src)\n","\n","# ratio test を使ったロバスト化\n","good_matches = []\n","\n","for m,n in matches:\n","    if m.distance < 0.75*n.distance:\n","        good_matches.append(m)\n","\n","# 全対応を可視化\n","corr_disp = cv2.drawMatches(ref,kp_ref,src,kp_src,good_matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","cv2_imshow(corr_disp) # 表示\n","\n","# 対応点の登録とホモグラフィ行列の推定（w/ RANSAC）\n","pts_ref = np.float32([ kp_ref[m.queryIdx].pt for m in good_matches]).reshape(-1,1,2)\n","pts_src = np.float32([ kp_src[m.trainIdx].pt  for m in good_matches]).reshape(-1,1,2)\n","H, mask = cv2.findHomography(pts_src, pts_ref, cv2.RANSAC,5.0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BMJrO680Nrv4"},"outputs":[],"source":["# 逆変換によるパノラマスティッチング（めんどいので最近傍法）\n","\n","dst = np.zeros((src.shape[0],src.shape[1]*2,3), dtype=np.uint8) # 横幅2倍の画像を生成(縦src.shape[0],横src.shape[1],3ch)\n","dst[0:ref.shape[0], 0:ref.shape[1], :] = ref # 最初に、refの画素値を先に入れておく（部分配列の操作）。3次元目は色なので、そのまま(:)\n","H_inv = np.linalg.inv(H)  # 逆行列\n","\n","for dst_y in range(dst.shape[0]):\n","  for dst_x in range(dst.shape[1]):\n","    dst_xyw = np.float32([dst_x, dst_y, 1]) # 同次座標\n","    src_xyw = H_inv.dot(dst_xyw)  # 変換\n","    src_x = src_xyw[0]/src_xyw[2] # 出力画像のX\n","    src_y = src_xyw[1]/src_xyw[2] # 出力画像のY\n","\n","    if src_x < 1 or src_y < 1 or src_x > src.shape[1]-2 or src_y > src.shape[0]-2:  # 画像の外側を参照しないようにする\n","      continue\n","\n","    dst[dst_y][dst_x] = src[int(src_y+0.5)][int(src_x+0.5)] # 最近傍法による補間\n","\n","\n","cv2_imshow(dst) # 表示"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Egk5k_cjxC3s"},"outputs":[],"source":["# 色補正：refとdstの間の重複部分の画素値から最小二乗法\n","\n","# refと変換後dstの重複領域をマスクとして計算\n","dst_ref = np.zeros((dst.shape[0],dst.shape[1],3), dtype=np.uint8)\n","dst_ref[0:ref.shape[0], 0:ref.shape[1], :] = ref  # 出力画像の座標における ref の画素値\n","\n","mask_ref = np.zeros((dst.shape[0],dst.shape[1]), dtype=bool)\n","mask_ref[0:ref.shape[0], 0:ref.shape[1]] = True  # refが存在する場所がTrue\n","\n","mask_src = np.zeros((dst.shape[0],dst.shape[1]), dtype=bool)\n","H_inv = np.linalg.inv(H)  # 逆行列\n","\n","for dst_y in range(mask_src.shape[0]):\n","  for dst_x in range(mask_src.shape[1]):\n","    dst_xyw = np.float32([dst_x, dst_y, 1]) # 同次座標\n","    src_xyw = H_inv.dot(dst_xyw)  # 変換\n","    src_x = src_xyw[0]/src_xyw[2] # 出力画像のX\n","    src_y = src_xyw[1]/src_xyw[2] # 出力画像のY\n","\n","    if src_x < 1 or src_y < 1 or src_x > src.shape[1]-2 or src_y > src.shape[0]-2:  # 画像の外側を参照しないようにする\n","      continue\n","\n","    mask_src[dst_y][dst_x] = True # src画素が存在する場所がTrue\n","\n","mask = mask_ref & mask_src  # 重複領域\n","cv2_imshow(mask*255)\n","\n","# src, refそれぞれの重複領域の画素値をnumpy arrayとして作成（3*N、nは重複領域の面積）\n","# ヒント：img[mask]とすると、maskがTrueの要素を取り出せる\n","Y = dst_ref[mask].transpose() # refの色を3*Nの行列にする\n","X = dst[mask].transpose() # srcの色を3*Nの行列にする。dstは、srcを変換して上書きして作ったので、重複領域のdstの画素値はsrcからとってきたもの\n","\n","# src -> refへの色補正行列の計算（線形最小二乗法を解く。講義スライド参照）\n","M = Y.dot(np.linalg.pinv(X))\n","\n","# 変換行列による画素値の変換\n","src_pixels = dst[mask_src].transpose()\n","src_corrected = (M@src_pixels).transpose()\n","src_corrected = np.clip(src_corrected, 0, 255)\n","dst[mask_src] = src_corrected\n","\n","# 表示\n","# サンプルの例では、周辺減光の影響で完全には色が一致しない。\n","# 重複領域をうまくアルファブレンディングすることで境目を目立たなくすることもできる。興味があれば試してみよう。\n","cv2_imshow(dst)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4LltLxQ3H8w"},"outputs":[],"source":["# Appendix: OpenCVにおけるワーピング関数（デフォルトでは逆変換の後バイリニア補間）\n","# https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#gaf73673a7e8e18ec6963e3774e6a94b87\n","dst_opencv = cv2.warpPerspective(src, H, (src.shape[1]*2,src.shape[0]))\n","\n","cv2_imshow(dst_opencv) # 表示"]}],"metadata":{"colab":{"provenance":[{"file_id":"16H8qhw0NZcUynH7VOasj111WOSGx5Mc6","timestamp":1607871684635}],"authorship_tag":"ABX9TyM5CdmPRwE2Qr7UA2lmz9Il"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}